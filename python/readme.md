# Bomberman PPO RL Projesi

Unity ile Bomberman tarzÄ± oyun geliÅŸtirip, oyuncuyu **PPO (Proximal Policy Optimization)** ile eÄŸiten makine Ã¶ÄŸrenmesi projesi.

## ğŸ¯ Proje Ã–zeti

- **Unity Environment**: 8 yÃ¶nlÃ¼ hareket, bomba yerleÅŸtirme, dÃ¼ÅŸmanlar, toplanabilir Ã¶ÄŸeler
- **PPO Agent**: Oyuncu karakterinin davranÄ±ÅŸlarÄ±nÄ± Ã¶ÄŸrenir
- **Procedural Generation**: Rastgele level Ã¼retimi
- **Curriculum Learning**: Zorluk seviyesi kademeli artÄ±rÄ±m
- **Comprehensive Monitoring**: DetaylÄ± performans takibi

## ğŸ“ Proje YapÄ±sÄ±

```
bomberman-ppo/
â”œâ”€â”€ Unity/                          # Unity projesi
â”‚   â”œâ”€â”€ Assets/
â”‚   â”‚   â”œâ”€â”€ Scripts/
â”‚   â”‚   â”‚   â”œâ”€â”€ PlayerAgent.cs      # ML-Agent player kontrolÃ¼
â”‚   â”‚   â”‚   â”œâ”€â”€ EnvManager.cs       # Ã‡evre yÃ¶netimi
â”‚   â”‚   â”‚   â”œâ”€â”€ RewardSystem.cs     # Ã–dÃ¼l sistemi
â”‚   â”‚   â”‚   â”œâ”€â”€ BombController.cs   # Bomba mantÄ±ÄŸÄ±
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ Prefabs/               # Oyun objeleri
â”‚   â”‚   â””â”€â”€ Scenes/                # Unity sahneleri
â”‚   â””â”€â”€ ProjectSettings/
â”œâ”€â”€ Python/                         # Python eÄŸitim kodu
â”‚   â”œâ”€â”€ train.py                   # Ana eÄŸitim scripti
â”‚   â”œâ”€â”€ evaluate.py                # Model deÄŸerlendirme
â”‚   â”œâ”€â”€ configs/
â”‚   â”‚   â””â”€â”€ ppo_config.yaml        # Hyperparameter ayarlarÄ±
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ wrappers.py            # Environment wrapper'larÄ±
â”‚   â”‚   â”œâ”€â”€ callbacks.py           # EÄŸitim callback'leri
â”‚   â”‚   â””â”€â”€ logger.py              # Logging utilities
â”‚   â””â”€â”€ requirements.txt           # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â”œâ”€â”€ models/                        # Kaydedilen modeller
â”œâ”€â”€ logs/                          # TensorBoard loglarÄ±
â”œâ”€â”€ checkpoints/                   # EÄŸitim checkpoint'leri
â””â”€â”€ README.md
```

## ğŸš€ Kurulum

### Unity Kurulumu

1. **Unity Hub ve Unity Editor yÃ¼kleyin** (2022.3 LTS Ã¶nerilen)

2. **ML-Agents paketini ekleyin**:
   ```
   Window > Package Manager > Add package by name:
   com.unity.ml-agents
   ```

3. **Proje dosyalarÄ±nÄ± Unity'ye ekleyin**:
   - Scriptleri `Assets/Scripts/` klasÃ¶rÃ¼ne kopyalayÄ±n
   - Prefab'larÄ± oluÅŸturun ve ayarlayÄ±n

### Python Kurulumu

1. **Python 3.8+ kurulumunu doÄŸrulayÄ±n**:
   ```bash
   python --version
   ```

2. **Gerekli paketleri yÃ¼kleyin**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Requirements.txt iÃ§eriÄŸi**:
   ```
   mlagents==0.30.0
   stable-baselines3==2.0.0
   gym-unity==0.28.0
   torch>=1.8.0
   tensorboard>=2.8.0
   matplotlib>=3.5.0
   seaborn>=0.11.0
   pyyaml>=6.0
   numpy>=1.21.0
   opencv-python>=4.5.0
   ```

## ğŸ® Unity Environment Kurulumu

### 1. Scene HazÄ±rlÄ±ÄŸÄ±

```csharp
// Temel GameObject'leri oluÅŸturun:
- GameManager (EnvManager script ekleyin)
- Player (PlayerAgent + RewardSystem scriptleri)
- Prefabs klasÃ¶rÃ¼ne: Wall, BreakableWall, Enemy, Collectible, Bomb, Exit
```

### 2. LayerMask AyarlarÄ±

```
Layers:
- Default (0): Genel objeler
- Wall (8): Duvarlar (hareket engeli)
- Enemy (9): DÃ¼ÅŸmanlar
- Player (10): Oyuncu
- Collectible (11): Toplanabilir Ã¶ÄŸeler
- Bomb (12): Bombalar
```

### 3. ML-Agents Behavior Parameters

```yaml
# PlayerAgent iÃ§in Behavior Parameters:
Behavior Name: BombermanPlayer
Vector Observation: 200+ (grid observations + distances + status)
Actions:
  - Discrete Branch 1: Movement (9 actions: 8 directions + no movement)
  - Discrete Branch 2: Bomb (2 actions: place bomb or not)
Model: (eÄŸitim sonrasÄ± atanacak)
```

## ğŸ§  EÄŸitim SÃ¼reci

### 1. KonfigÃ¼rasyon Ayarlama

`configs/ppo_config.yaml` dosyasÄ±nÄ± ihtiyaÃ§larÄ±nÄ±za gÃ¶re dÃ¼zenleyin:

```yaml
# Temel ayarlar
training:
  total_timesteps: 2000000
  n_envs: 8
  device: "auto"

# PPO hiperparametreleri
ppo:
  learning_rate: 3.0e-4
  n_steps: 2048
  batch_size: 64
  gamma: 0.99
```

### 2. EÄŸitimi BaÅŸlatma

```bash
# Temel eÄŸitim
python train.py --config configs/ppo_config.yaml

# Varolan modelden devam etme
python train.py --config configs/ppo_config.yaml --resume models/bomberman_ppo_checkpoint_1000000

# Ã–zel ayarlarla eÄŸitim
python train.py --config configs/ppo_config.yaml --total-timesteps 5000000
```

### 3. EÄŸitimi Ä°zleme

```bash
# TensorBoard'u baÅŸlatÄ±n
tensorboard --logdir logs/

# Browser'da aÃ§Ä±n: http://localhost:6006
```

## ğŸ“Š Model DeÄŸerlendirme

### Temel DeÄŸerlendirme

```bash
# EÄŸitilmiÅŸ modeli test etme
python evaluate.py --model models/bomberman_ppo_final.zip --episodes 100

# GÃ¶rselleÅŸtirme ile test
python evaluate.py --model models/bomberman_ppo_final.zip --episodes 10 --render
```

### Model KarÅŸÄ±laÅŸtÄ±rma

```bash
# Birden fazla modeli karÅŸÄ±laÅŸtÄ±rma
python evaluate.py --compare models/model1.zip models/model2.zip models/model3.zip --episodes 50
```

### Benchmark Testi

```bash
# FarklÄ± zorluk seviyelerinde test
python evaluate.py --model models/bomberman_ppo_final.zip --benchmark --episodes 20
```

## ğŸ¯ Ã–dÃ¼l Sistemi

### Pozitif Ã–dÃ¼ller
- **Level Tamamlama**: +10.0
- **DÃ¼ÅŸman Ã–ldÃ¼rme**: +2.0
- **Toplanabilir Ã–ÄŸe**: +1.0 - +2.0
- **Duvar KÄ±rma**: +0.2
- **Bomba YerleÅŸtirme**: +0.1

### Negatif Cezalar
- **Ã–lÃ¼m**: -5.0
- **Hasar Alma**: -1.0
- **Duvara Ã‡arpma**: -0.1
- **Hareketsizlik**: -0.02
- **Zaman AÅŸÄ±mÄ±**: -2.0

### Mesafe TabanlÄ± Ã–dÃ¼ller
- DÃ¼ÅŸmana yaklaÅŸma: +0.01
- Ã‡Ä±kÄ±ÅŸa yaklaÅŸma: +0.02
- Toplanabilir Ã¶ÄŸeye yaklaÅŸma: +0.01

## ğŸšï¸ Curriculum Learning

EÄŸitim zorluk seviyeleri kademeli olarak artar:

1. **Beginner**: 1 dÃ¼ÅŸman, kÃ¼Ã§Ã¼k harita (11x11)
2. **Intermediate**: 2 dÃ¼ÅŸman, orta harita (13x13)
3. **Advanced**: 3 dÃ¼ÅŸman, bÃ¼yÃ¼k harita (15x15)
4. **Expert**: 4 dÃ¼ÅŸman, maksimum zorluk

## ğŸ”§ Troubleshooting

### YaygÄ±n Sorunlar

1. **Unity ML-Agents baÄŸlantÄ± hatasÄ±**:
   ```
   Ã‡Ã¶zÃ¼m: Unity'de Play modunda olduÄŸunuzdan emin olun
   Port Ã§akÄ±ÅŸmasÄ± varsa worker_id deÄŸiÅŸtirin
   ```

2. **Python import hatasÄ±**:
   ```bash
   pip install --upgrade mlagents
   pip install --upgrade stable-baselines3
   ```

3. **CUDA/GPU sorunlarÄ±**:
   ```yaml
   # config dosyasÄ±nda:
   training:
     device: "cpu"  # GPU yerine CPU kullan
   ```

4. **Memory hatasÄ±**:
   ```yaml
   # Batch size'Ä± kÃ¼Ã§Ã¼ltÃ¼n:
   ppo:
     batch_size: 32  # 64 yerine
     n_steps: 1024   # 2048 yerine
   ```

### Debug Modunda Ã‡alÄ±ÅŸtÄ±rma

```bash
# Verbose logging ile
python train.py --config configs/ppo_config.yaml --verbose

# Tek environment ile test
python train.py --config configs/ppo_config.yaml --n-envs 1 --no-graphics false
```

## ğŸ“ˆ Performans Optimizasyonu

### Unity Optimizasyonu
- Graphics Quality: Fast/Fastest
- VSync: Disabled
- Target Frame Rate: 60
- No Graphics mode: Training iÃ§in aktif

### Python Optimizasyonu
- Multi-environment: 4-8 parallel env
- Buffer size: GPU memory'ye gÃ¶re ayarlayÄ±n
- Checkpoint frequency: Disk I/O'yu dengeyin

## ğŸš€ GeliÅŸmiÅŸ Ã–zellikler

### Multi-Agent Training
```yaml
# Gelecek sÃ¼rÃ¼mde:
multi_agent:
  enabled: true
  n_agents: 2
  competitive: true
```

### Self-Play
```yaml
experimental:
  self_play: true
  opponent_pool_size: 5
```

### Hyperparameter Tuning
```bash
# Optuna ile otomatik hyperparameter tuning
python tune_hyperparams.py --config configs/tuning_config.yaml
```

## ğŸ“š Kaynaklar

- [Unity ML-Agents Documentation](https://github.com/Unity-Technologies/ml-agents)
- [Stable-Baselines3 Documentation](https://stable-baselines3.readthedocs.io/)
- [PPO Paper](https://arxiv.org/abs/1707.06347)
- [Curriculum Learning](https://arxiv.org/abs/1904.03733)

## ğŸ¤ KatkÄ±da Bulunma

1. Fork yapÄ±n
2. Feature branch oluÅŸturun (`git checkout -b feature/amazing-feature`)
3. Commit yapÄ±n (`git commit -m 'Add amazing feature'`)
4. Push yapÄ±n (`git push origin feature/amazing-feature`)
5. Pull Request aÃ§Ä±n

## ğŸ“„ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in `LICENSE` dosyasÄ±na bakÄ±n.

## âš¡ HÄ±zlÄ± BaÅŸlangÄ±Ã§

```bash
# 1. Repository'yi klonlayÄ±n
git clone <repo-url>
cd bomberman-ppo

# 2. Python baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± yÃ¼kleyin
pip install -r requirements.txt

# 3. Unity'de projeyi aÃ§Ä±n ve Play yapÄ±n

# 4. EÄŸitimi baÅŸlatÄ±n
python train.py

# 5. TensorBoard ile izleyin
tensorboard --logdir logs/
```

BaÅŸarÄ±lÄ± eÄŸitimler! ğŸ®ğŸ¤–